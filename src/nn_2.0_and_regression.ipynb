{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9eca70",
   "metadata": {},
   "source": [
    "# NN 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006067bb",
   "metadata": {},
   "source": [
    "## Defining data functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32215fac",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dbd29",
   "metadata": {},
   "source": [
    "Get data from file and remove columns with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swissvotes_data()->pd.DataFrame:\n",
    "    import re\n",
    "    \n",
    "    dataset = pd.read_csv(\"../data/formatted/swissvotes_dataset_after_1900_utf8.csv\", sep=';')\n",
    "    \n",
    "    regex = re.compile(\"pdev_.*\")\n",
    "    to_excl = list(filter(regex.match, dataset.columns))\n",
    "    \n",
    "    dataset.drop(columns=to_excl, inplace=True)\n",
    "    dataset.drop(columns=[\"legisjahr\"], inplace=True)\n",
    "    dataset.drop(columns=[\"titel_kurz_d\", \"titel_kurz_f\", \"titel_off_d\", \"titel_off_f\", \"stichwort\"], inplace=True)\n",
    "    dataset.drop(columns=[\"swissvoteslink\", \"anzahl\", \"anneepolitique\", \"bkchrono_de\", \"bkchrono_fr\"], inplace=True)\n",
    "    dataset.drop(columns=[\"curiavista_de\", \"curiavista_fr\", \"urheber\", \"bkresults_de\", \"bkresults_fr\"], inplace=True)\n",
    "    dataset.drop(columns=[\"bfsmap_de\", \"bfsmap_fr\", \"nach_cockpit_d\", \"nach_cockpit_f\", \"nach_cockpit_e\"], inplace=True)\n",
    "    dataset = dataset[dataset[\"anr\"] < 646] # we don't care about future votes\n",
    "    \n",
    "    return dataset\n",
    "print(f\"Defined {get_swissvotes_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721da4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rechtsform_onehot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    tensor = tf.one_hot(data[\"rechtsform\"], 5).numpy();\n",
    "    result = pd.DataFrame(tensor, columns=[\"ref_obl\", \"ref_fak\", \"initiative\", \"gegen_entw\", \"stichfr\"], index=data.index)\n",
    "    \n",
    "    return result.astype(int)\n",
    "print(f\"Defined {get_rechtsform_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_politikbereich_multihot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    polber = data[[\"d1e1\", \"d2e1\", \"d3e1\"]]\n",
    "    polber = polber.replace('.', 0)\n",
    "    polber = polber.astype(int)\n",
    "    \n",
    "    # the names of the columns (they're a bit long)\n",
    "    cols = [\"Staatsordnung\", \"Aussenpolitik\", \"Sicherheitspolitik\", \"Wirtschaft\"]\n",
    "    cols += [\"Landwirtschaft\", \"Öffentliche Finanzen\", \"Energie\", \"Verkehr und Infrastruktur\"]\n",
    "    cols += [\"Umwelt und Lebensraum\", \"Sozialpolitik\", \"Bildung und Forschung\", \"Kultur, Religion, Medien\"]\n",
    "    \n",
    "    result = pd.DataFrame(columns=cols, index = data.index)\n",
    "    for i in range(len(result)):\n",
    "        row = np.zeros(12)\n",
    "        for p in polber.iloc[i]:\n",
    "            if p != 0:\n",
    "                row[p-1] = 1\n",
    "        result.iloc[i] = row\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_politikbereich_multihot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_department_onehot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    dep_single = data[\"dep\"].replace('.', 2) # voting at age 18 is the only vote with a '.' and it's dep of inner\n",
    "    dep_single = dep_single.astype(int)\n",
    "    tensor = tf.one_hot(dep_single, 8).numpy()\n",
    "    result = pd.DataFrame(tensor, columns=[\"EDA\", \"EDI\", \"EJPD\", \"VBS\", \"EFD\", \"WBF\", \"UVEK\", \"BK\"], index=data.index)\n",
    "    \n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_department_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82965ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bundesrat_onehot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    tensor = tf.one_hot(data[\"br_pos\"].replace('.', 3).astype(int), 3).numpy()\n",
    "    result = pd.DataFrame(tensor, columns=[\"Dafür_bund\", \"Dagegen_bund\", \"Keine_bund\"], index=data.index)\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_bundesrat_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4dd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legislatur(low:int=1, high:int=10, data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    leg = data[\"legislatur\"]\n",
    "    def my_map(x:int, x_min:int=leg.min(0), x_max:int=leg.max(0), y_min:int=low, y_max:int=high)->float:\n",
    "        return (x-x_min)/(x_max-x_min)*(y_max-y_min)+y_min\n",
    "    \n",
    "    normalized = data[[\"legislatur\"]].applymap(my_map)\n",
    "    return normalized\n",
    "\n",
    "print(f\"Defined {get_legislatur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2633d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nationalrat_onehot(data:pd.DataFrame = get_swissvotes_data()[\"nr_pos\"])->pd.DataFrame:\n",
    "    tensor = tf.one_hot(data.astype(int), 3).numpy()\n",
    "    result = pd.DataFrame(tensor, columns=[\"Dafür_nat\", \"Dagegen_nat\", \"Keine_nat\"], index=data.index)\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_nationalrat_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ständerat_onehot(data:pd.DataFrame = get_swissvotes_data()[\"sr_pos\"])->pd.DataFrame:\n",
    "    tensor = tf.one_hot(data.astype(int), 3).numpy()\n",
    "    result = pd.DataFrame(tensor, columns=[\"Dafür_std\", \"Dagegen_std\", \"Keine_std\"], index=data.index)\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_ständerat_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parties(data:pd.DataFrame = get_swissvotes_data())->list:\n",
    "    import re\n",
    "    \n",
    "    regex_incl = re.compile(\"p_.*\")\n",
    "    regex_excl = re.compile(\"p_others_.*\")\n",
    "    \n",
    "    parties_pre = list(filter(regex_incl.match, data.columns))\n",
    "    parties = [p for p in parties_pre if not regex_excl.match(p)]\n",
    "    return parties\n",
    "\n",
    "print(f\"Defined {get_parties}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_party_reco(data:pd.DataFrame = get_swissvotes_data(), names:list = get_parties())->pd.DataFrame:\n",
    "    # deal with unwanted values first\n",
    "    normalized = data[names].replace(\".\", 0)\n",
    "    normalized.replace(np.nan, 0, inplace=True)\n",
    "    normalized = normalized.astype(int)\n",
    "    normalized.replace([3,4,5,66,9999], 0, inplace=True)\n",
    "    \n",
    "    result = pd.DataFrame(index=normalized.index)\n",
    "    \n",
    "    for p in names: # go through parties and create one hot encoding\n",
    "        tensor = tf.one_hot(normalized[p], 3).numpy()\n",
    "        temp = pd.DataFrame(tensor, columns=[p+\"_neutral\", p+\"_ja\", p+\"_nein\"], index=result.index)\n",
    "        result = result.join(temp)\n",
    "\n",
    "    return result.astype(int)\n",
    "print(f\"Defined {normalize_party_reco}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vote_result(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    result = data[\"annahme\"].replace('.', 0)\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_vote_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fcd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataframe \n",
    "def get_canton_results(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    import re\n",
    "    regex = re.compile(\".*_annahme\")\n",
    "    canton_names = list(filter(regex.match, data.columns))\n",
    "    return data[canton_names].replace('.', 0).astype(int)\n",
    "\n",
    "print(f\"Defined {get_canton_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ac03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vote_result_proz(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    result = data[\"volkja_proz\"].replace('.', 0)\n",
    "    result = result.apply(lambda x: x/100)\n",
    "    return result.astype(float)\n",
    "\n",
    "print(f\"Defined {get_vote_result_proz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataframe \n",
    "def get_canton_results_proz(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    import re\n",
    "    regex = re.compile(\".*_japroz\")\n",
    "    canton_names = list(filter(regex.match, data.columns))\n",
    "    result = data[canton_names].replace('.', 0)\n",
    "    result.dropna(inplace=True)\n",
    "    result = result.apply(lambda x: x/100)\n",
    "    return result.astype(float)\n",
    "\n",
    "print(f\"Defined {get_canton_results_proz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb520f0e",
   "metadata": {},
   "source": [
    "## Training the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "def get_data():\n",
    "    swissvotes = get_swissvotes_data()\n",
    "    # the inputs used by the neural net are:\n",
    "        # Rechtsform (one hot),\n",
    "        # Politikbereich (multi hot),\n",
    "        # Department (one hot),\n",
    "        # Position of the Bundesrat (one hot),\n",
    "        # legislatur (normalized from 1-10),\n",
    "        # Position of Nationalrat (one hot),\n",
    "        # Position of Ständerat (one hot),\n",
    "        # Party recommendations (one hot)\n",
    "    in_rchtfrm = get_rechtsform_onehot()\n",
    "    in_poltber = get_politikbereich_multihot()\n",
    "    in_deprtmt = get_department_onehot()\n",
    "    in_burapos = get_bundesrat_onehot()\n",
    "    in_legsltr = get_legislatur()\n",
    "    in_narapos = get_nationalrat_onehot()\n",
    "    in_strapos = get_ständerat_onehot()\n",
    "    in_parties = normalize_party_reco()\n",
    "    \n",
    "    inputs = pd.concat([in_rchtfrm, in_poltber, in_deprtmt, in_burapos, in_narapos, in_strapos, in_parties, in_legsltr], axis=1)\n",
    "    \n",
    "    # the outputs are:\n",
    "        # result of the votes (binary),\n",
    "        # result on a canton level (binary)\n",
    "    out_result = get_vote_result()\n",
    "    out_canton = get_canton_results()\n",
    "    \n",
    "    outputs = pd.concat([out_result, out_canton], axis=1)\n",
    "    \n",
    "    return swissvotes, inputs, outputs\n",
    "\n",
    "print(f\"Defined {get_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d227986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_size:int = len(get_data()[1].columns), hidden:list=[100, 50, 20],\n",
    "                 output_size:int = len(get_data()[2].columns), activation:str=\"relu\",\n",
    "                 activation_output:str=\"sigmoid\", \n",
    "                 optimizer=ks.optimizers.SGD(learning_rate=0.1), \n",
    "                 loss=ks.losses.BinaryCrossentropy())->ks.models.Sequential:\n",
    "    model = ks.models.Sequential()\n",
    "    \n",
    "    model.add(ks.layers.Dense(units=input_size, activation=activation, name=\"Input\"))\n",
    "    \n",
    "    for i in range(len(hidden)):\n",
    "        model.add(ks.layers.Dense(units=hidden[i], activation=activation, name=\"Hidden_\"+str(i)))\n",
    "        model.add(ks.layers.Dropout(rate=.1, name=\"Dropout_\"+str(i)))\n",
    "        \n",
    "    model.add(ks.layers.Dense(units=output_size, activation=activation_output, name=\"Output\"))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[ks.metrics.BinaryAccuracy(), \n",
    "                                                           ks.metrics.FalseNegatives()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(f\"Defined {create_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d38517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:ks.models.Sequential, inputs:pd.DataFrame=get_data()[1], \n",
    "                outputs:pd.DataFrame=get_data()[2], test_size:float=0.2, \n",
    "                batch_size:int=50, epochs:int=75, shuffle:bool=True)->tuple:\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    in_train, in_test, out_train, out_test = tts(inputs, outputs, test_size=test_size)\n",
    "    \n",
    "    history = model.fit(x=in_train, y=out_train, batch_size=batch_size, epochs=epochs, shuffle=shuffle)\n",
    "    \n",
    "    return history, in_test, out_test\n",
    "\n",
    "print(f\"Defined {train_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(hidden=[10, 20], \n",
    "                     loss=ks.losses.MeanAbsoluteError(), activation_output=\"sigmoid\")\n",
    "\n",
    "history, in_test, out_test = train_model(model, epochs=125)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=in_test, y=out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b22faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118bc5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(inputs:pd.DataFrame=get_data()[1],\n",
    "                     outputs:pd.DataFrame=get_data()[2]['annahme'],\n",
    "                     test_size:float=0.2, cutoff:float=.5,\n",
    "                     shuffle:bool=False, scale_data:bool=False,\n",
    "                     visualisation:bool=True, in_train:pd.DataFrame=None,\n",
    "                     in_test:pd.DataFrame=None, out_train:list=None, out_test:list=None)->tuple:\n",
    "    if in_train is None or in_test is None or out_train is None or out_test is None:\n",
    "        from sklearn.model_selection import train_test_split as tts\n",
    "        cutoff=int(cutoff*len(inputs))\n",
    "        in_train, in_test, out_train, out_test = tts(inputs[cutoff:], outputs[cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "    else: assert len(in_train)==len(out_train) and len(in_test)==len(out_test)\n",
    "    \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    from sklearn.linear_model import SGDClassifier, RidgeClassifier, RidgeClassifierCV\n",
    "    from xgboost import XGBClassifier\n",
    "    #from fracridge import FracRidgeRegressor, FracRidgeRegressorCV\n",
    "    ridge = RidgeClassifier()\n",
    "    ridge.fit(in_train,out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(in_test)])\n",
    "    \n",
    "    ridgecv = RidgeClassifierCV()\n",
    "    ridgecv.fit(in_train,out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(in_test)])\n",
    "    \n",
    "    #fracridge = FracRidgeRegressor()\n",
    "    #fracridge.fit(in_train,out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(in_test)])\n",
    "    \n",
    "    #fracridgecv = FracRidgeRegressorCV()\n",
    "    #fracridgecv.fit(in_train,out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(in_test)])\n",
    "    \n",
    "    sgd = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "    sgd.fit(in_train, out_train)\n",
    "    out_pred.append([sgd,'sgd', sgd.predict(in_test)])\n",
    "    \n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(in_train, out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(in_test)])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        from sklearn.metrics import plot_confusion_matrix\n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            plot_confusion_matrix(i[0],in_test,out_test)\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0c7f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_classifier(shuffle=True,test_size=0.01,visualisation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17346ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_outcomes_proz():\n",
    "    out_result_proz = get_vote_result_proz()\n",
    "    out_canton_proz = get_canton_results_proz()\n",
    "    \n",
    "    outputs_proz = pd.concat([out_result_proz, out_canton_proz], axis=1)\n",
    "    \n",
    "    return outputs_proz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d251d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(inputs:pd.DataFrame=get_data()[1],\n",
    "                     outputs:pd.DataFrame=get_outcomes_proz()['volkja_proz'],\n",
    "                     test_size:float=0.2, cutoff:float=.5,\n",
    "                     shuffle:bool=False, scale_data:bool=False,\n",
    "                     visualisation:bool=True, in_train:pd.DataFrame=None,\n",
    "                     in_test:pd.DataFrame=None, out_train:list=None, out_test:list=None)->tuple:\n",
    "    if in_train is None or in_test is None or out_train is None or out_test is None:\n",
    "        from sklearn.model_selection import train_test_split as tts\n",
    "        cutoff=int(cutoff*len(inputs))\n",
    "        in_train, in_test, out_train, out_test = tts(inputs[cutoff:], outputs[cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "    else: assert len(in_train)==len(out_train) and len(in_test)==len(out_test)\n",
    "        \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "    from xgboost import XGBRegressor\n",
    "    ridge = Ridge()\n",
    "    ridge.fit(in_train,out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(in_test)])\n",
    "    \n",
    "    ridgecv = RidgeCV()\n",
    "    ridgecv.fit(in_train,out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(in_test)])\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(in_train,out_train)\n",
    "    out_pred.append([lasso,'lasso', lasso.predict(in_test)])\n",
    "    \n",
    "    lassocv = LassoCV()\n",
    "    lassocv.fit(in_train,out_train)\n",
    "    out_pred.append([lassocv,'lassocv', lassocv.predict(in_test)])\n",
    "    \n",
    "    elasticnet = ElasticNet()\n",
    "    elasticnet.fit(in_train,out_train)\n",
    "    out_pred.append([elasticnet,'elasticnet', elasticnet.predict(in_test)])\n",
    "    \n",
    "    elasticnetcv = ElasticNetCV()\n",
    "    elasticnetcv.fit(in_train,out_train)\n",
    "    out_pred.append([elasticnetcv,'elasticnetcv', elasticnetcv.predict(in_test)])\n",
    "    \n",
    "    xgb = XGBRegressor()\n",
    "    xgb.fit(in_train,out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(in_test)])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74ac3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_regression(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(inputs:pd.DataFrame=get_data()[1],\n",
    "          outputs:pd.DataFrame=get_data()[2]):\n",
    "    fig, ax = plt.subplots(3,1, figsize=(20,30))\n",
    "    ax[0].hist(inputs['legislatur'], bins=34)\n",
    "    \n",
    "    ax[1].hist(outputs['annahme'], bins=34)\n",
    "    \n",
    "    ax[2]=sns.lineplot(x=inputs['legislatur'], y=outputs['annahme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a049c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iv_classifier(inputs:pd.DataFrame=get_data()[1], middle:pd.DataFrame=get_data()[2].drop(columns=['annahme']),\n",
    "                  outputs:pd.DataFrame=get_data()[2]['annahme'],test_size:float=0.2, cutoff:float=.5,\n",
    "                  shuffle:bool=False, scale_data:bool=False,visualisation:bool=True)->tuple:\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    cutoff=int(cutoff*len(inputs))\n",
    "    in_train, in_test, mid_train, mid_test = tts(inputs[cutoff:], middle[cutoff:], test_size=0.01, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    #print(middle.columns)\n",
    "    mid_pred=[]\n",
    "    from sklearn.linear_model import SGDClassifier, RidgeClassifier, RidgeClassifierCV\n",
    "    from xgboost import XGBClassifier\n",
    "    #from fracridge import FracRidgeRegressor, FracRidgeRegressorCV\n",
    "    mid_ridge=[]\n",
    "    for i in middle.columns:\n",
    "        ridge = RidgeClassifier()\n",
    "        ridge.fit(in_train,mid_train[i])\n",
    "        mid_ridge.append(ridge.predict(inputs))\n",
    "    mid_ridge=np.transpose(mid_ridge)\n",
    "    mid_pred.append(pd.DataFrame(mid_ridge,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_ridgecv=[]\n",
    "    for i in middle.columns:\n",
    "        ridgecv = RidgeClassifierCV()\n",
    "        ridgecv.fit(in_train,mid_train[i])\n",
    "        mid_ridgecv.append(ridgecv.predict(inputs))\n",
    "    mid_ridgecv=np.transpose(mid_ridgecv)\n",
    "    mid_pred.append(pd.DataFrame(mid_ridgecv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    #mid_fracrdige=[]\n",
    "    #for i in middle.columns:\n",
    "    #    fracridge = FracRidgeRegressor()\n",
    "    #    fracridge.fit(in_train,mid_train[i])\n",
    "    #    mid_fracridge.append(fracridge.predict(inputs))\n",
    "    #mid_fracridge=np.transpose(mid_fracridge)\n",
    "    #mid_pred.append(pd.DataFrame(mid_fracridge,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    #mid_fracridgecv=[]\n",
    "    #for i in middle.columns:\n",
    "    #    fracridgecv = FracRidgeRegressorCV()\n",
    "    #    fracridgecv.fit(in_train,mid_train[i])\n",
    "    #    mid_fracridgecv.append(fracridgecv.predict(inputs))\n",
    "    #mid_fracridgecv=np.transpose(mid_fracridgecv)\n",
    "    #mid_pred.append(pd.DataFrame(mid_fracridgecv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_sgd=[]\n",
    "    for i in middle.columns:\n",
    "        sgd = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "        sgd.fit(in_train,mid_train[i])\n",
    "        mid_sgd.append(sgd.predict(inputs))\n",
    "    mid_sgd=np.transpose(mid_sgd)\n",
    "    mid_pred.append(pd.DataFrame(mid_sgd,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_xgb=[]\n",
    "    for i in middle.columns:\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(in_train,mid_train[i])\n",
    "        mid_xgb.append(xgb.predict(inputs))\n",
    "    mid_xgb=np.transpose(mid_xgb)\n",
    "    mid_pred.append(pd.DataFrame(mid_xgb,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_train = [] \n",
    "    mid_test = []\n",
    "    for i in np.arange(0,len(mid_pred)):\n",
    "        mid_t1, mid_t2 = tts(mid_pred[i][cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "        mid_train.append(mid_t1)\n",
    "        mid_test.append(mid_t2)\n",
    "    out_train, out_test = tts(outputs[cutoff:],test_size=test_size, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        for i in np.arange(0,len(mid_train)):\n",
    "            scaler = StandardScaler().fit(mid_train[i])\n",
    "            mid_train[i] = scaler.transform(mid_train[i])\n",
    "            mid_test[i] = scaler.transform(mid_test[i])\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    ridge = RidgeClassifier()\n",
    "    ridge.fit(mid_train[0],out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(mid_test[1])])\n",
    "    \n",
    "    ridgecv = RidgeClassifierCV()\n",
    "    ridgecv.fit(mid_train[1],out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(mid_test[1])])\n",
    "    \n",
    "    #fracridge = FracRidgeRegressor()\n",
    "    #fracridge.fit(mid_train[i],out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(mid_test[i])])\n",
    "    \n",
    "    #fracridgecv = FracRidgeRegressorCV()\n",
    "    #fracridgecv.fit(mid_train[i],out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(mid_test[i])])\n",
    "    \n",
    "    sgd = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "    sgd.fit(mid_train[2], out_train)\n",
    "    out_pred.append([sgd,'sgd', sgd.predict(mid_test[2])])\n",
    "    \n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(mid_train[3], out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(mid_test[3])])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_classifier(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636d109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fad23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f08b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef6f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
