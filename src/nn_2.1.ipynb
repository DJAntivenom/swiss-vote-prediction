{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9eca70",
   "metadata": {},
   "source": [
    "# NN 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006067bb",
   "metadata": {},
   "source": [
    "## Defining data functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32215fac",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dbd29",
   "metadata": {},
   "source": [
    "Get data from file and remove columns with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swissvotes_data(now:int=646)->pd.DataFrame:\n",
    "    import re\n",
    "    \n",
    "    dataset = pd.read_csv(\"../data/formatted/swissvotes_dataset_after_1900_utf8.csv\", sep=';')\n",
    "    \n",
    "    regex = re.compile(\"pdev_.*\")\n",
    "    to_excl = list(filter(regex.match, dataset.columns))\n",
    "    \n",
    "    dataset.drop(columns=to_excl, inplace=True)\n",
    "    dataset.drop(columns=[\"legisjahr\"], inplace=True)\n",
    "    dataset.drop(columns=[\"titel_kurz_d\", \"titel_kurz_f\", \"titel_off_d\", \"titel_off_f\", \"stichwort\"], inplace=True)\n",
    "    dataset.drop(columns=[\"swissvoteslink\", \"anzahl\", \"anneepolitique\", \"bkchrono_de\", \"bkchrono_fr\"], inplace=True)\n",
    "    dataset.drop(columns=[\"curiavista_de\", \"curiavista_fr\", \"urheber\", \"bkresults_de\", \"bkresults_fr\"], inplace=True)\n",
    "    dataset.drop(columns=[\"bfsmap_de\", \"bfsmap_fr\", \"nach_cockpit_d\", \"nach_cockpit_f\", \"nach_cockpit_e\"], inplace=True)\n",
    "    dataset = dataset[dataset[\"anr\"] < now] # we don't care about future votes\n",
    "    \n",
    "    return dataset\n",
    "print(f\"Defined {get_swissvotes_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66726f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_right_data(now:int=646)->pd.DataFrame:\n",
    "    col_names = [\"anr\", \"datum\", \"titel_kurz_d\", \"ja_proz\", \"links_rechts\", \"kons_prog\"]\n",
    "    dataset = pd.read_csv(\"../data/formatted/brj_lire_konslib_edited.csv\", sep=',')\n",
    "    dataset = dataset[dataset[\"anr\"].map(lambda x: x.replace(',', '.')).astype(float) < now]\n",
    "    dataset = dataset.replace(\"#ZAHL!\", np.nan).replace(\"Nan\", np.nan)\n",
    "    \n",
    "    return dataset.drop(columns=[\"titel_kurz\"])\n",
    "\n",
    "print(f\"Defined {get_left_right_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l_r_onehot(data:pd.DataFrame=get_left_right_data()[\"li_re\"])->pd.DataFrame:\n",
    "    temp = data.replace(np.nan, 4).astype(int)\n",
    "    temp += 3\n",
    "    tensor = tf.one_hot(temp, 8).numpy()\n",
    "    \n",
    "    temp = pd.DataFrame(tensor, columns=[\"l3\", \"l2\", \"l1\", \"nlr\", \"r1\", \"r2\", \"r3\", \"del\"], index=data.index)\n",
    "    return temp.drop(columns=[\"del\"])\n",
    "\n",
    "print(f\"Defined {get_l_r_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619bc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kons_prog_onehot(data:pd.DataFrame=get_left_right_data()[\"kons_prog\"])->pd.DataFrame:\n",
    "    temp = data.replace(np.nan, 4).astype(int)\n",
    "    temp += 3\n",
    "    tensor = tf.one_hot(temp, 8).numpy()\n",
    "    \n",
    "    temp = pd.DataFrame(tensor, columns=[\"k3\", \"k2\", \"k1\", \"nkp\", \"p1\", \"p2\", \"p3\", \"del\"], index=data.index)\n",
    "    return temp.drop(columns=[\"del\"])\n",
    "\n",
    "print(f\"Defined {get_kons_prog_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721da4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rechtsform_onehot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    tensor = tf.one_hot(data[\"rechtsform\"], 5).numpy();\n",
    "    result = pd.DataFrame(tensor, columns=[\"ref_obl\", \"ref_fak\", \"initiative\", \"gegen_entw\", \"stichfr\"], index=data.index)\n",
    "    \n",
    "    return result.astype(int)\n",
    "print(f\"Defined {get_rechtsform_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_politikbereich_multihot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    polber = data[[\"d1e1\", \"d2e1\", \"d3e1\"]]\n",
    "    polber = polber.replace('.', 0)\n",
    "    polber = polber.astype(int)\n",
    "    \n",
    "    # the names of the columns (they're a bit long)\n",
    "    cols = [\"Staatsordnung\", \"Aussenpolitik\", \"Sicherheitspolitik\", \"Wirtschaft\"]\n",
    "    cols += [\"Landwirtschaft\", \"Öffentliche Finanzen\", \"Energie\", \"Verkehr und Infrastruktur\"]\n",
    "    cols += [\"Umwelt und Lebensraum\", \"Sozialpolitik\", \"Bildung und Forschung\", \"Kultur, Religion, Medien\"]\n",
    "    \n",
    "    result = pd.DataFrame(columns=cols, index = data.index)\n",
    "    for i in range(len(result)):\n",
    "        row = np.zeros(12)\n",
    "        for p in polber.iloc[i]:\n",
    "            if p != 0:\n",
    "                row[p-1] = 1\n",
    "        result.iloc[i] = row\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_politikbereich_multihot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_department_onehot(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    dep_single = data[\"dep\"].replace('.', 2) # voting at age 18 is the only vote with a '.' and it's dep of inner\n",
    "    dep_single = dep_single.astype(int)\n",
    "    tensor = tf.one_hot(dep_single, 8).numpy()\n",
    "    result = pd.DataFrame(tensor, columns=[\"EDA\", \"EDI\", \"EJPD\", \"VBS\", \"EFD\", \"WBF\", \"UVEK\", \"BK\"], index=data.index)\n",
    "    \n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_department_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4dd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legislatur(low:int=1, high:int=10, data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    leg = data[\"legislatur\"]\n",
    "    def my_map(x:int, x_min:int=leg.min(0), x_max:int=leg.max(0), y_min:int=low, y_max:int=high)->float:\n",
    "        return (x-x_min)/(x_max-x_min)*(y_max-y_min)+y_min\n",
    "    \n",
    "    normalized = data[[\"legislatur\"]].applymap(my_map)\n",
    "    return normalized\n",
    "\n",
    "print(f\"Defined {get_legislatur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2633d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parlament_onehot(data:pd.DataFrame = get_swissvotes_data()[\"nr_pos\"])->pd.DataFrame:\n",
    "    tensor = tf.one_hot(data.replace('.', 3).astype(int), 3).numpy()\n",
    "    result = pd.DataFrame(tensor, columns=[\"Für_\"+data.name, \n",
    "                                           \"Dagegen_\"+data.name, \n",
    "                                           \"Keine_\"+data.name], index=data.index)\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_parlament_onehot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parties(data:pd.DataFrame = get_swissvotes_data())->list:\n",
    "    import re\n",
    "    \n",
    "    regex_incl = re.compile(\"p_.*\")\n",
    "    regex_excl = re.compile(\"p_others_.*\")\n",
    "    \n",
    "    parties_pre = list(filter(regex_incl.match, data.columns))\n",
    "    parties = [p for p in parties_pre if not regex_excl.match(p)]\n",
    "    return parties\n",
    "\n",
    "print(f\"Defined {get_parties}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_party_reco(data:pd.DataFrame = get_swissvotes_data(), names:list = get_parties())->pd.DataFrame:\n",
    "    # deal with unwanted values first\n",
    "    normalized = data[names].replace(\".\", 0)\n",
    "    normalized.replace(np.nan, 0, inplace=True)\n",
    "    normalized = normalized.astype(int)\n",
    "    normalized.replace([3,4,5,66,9999], 0, inplace=True)\n",
    "    \n",
    "    result = pd.DataFrame(index=normalized.index)\n",
    "    \n",
    "    for p in names: # go through parties and create one hot encoding\n",
    "        tensor = tf.one_hot(normalized[p], 3).numpy()\n",
    "        temp = pd.DataFrame(tensor, columns=[p+\"_neutral\", p+\"_ja\", p+\"_nein\"], index=result.index)\n",
    "        result = result.join(temp)\n",
    "\n",
    "    return result.astype(int)\n",
    "print(f\"Defined {normalize_party_reco}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vote_result(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    result = data[\"annahme\"].replace('.', 0)\n",
    "    return result.astype(int)\n",
    "\n",
    "print(f\"Defined {get_vote_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fcd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataframe \n",
    "def get_canton_results(data:pd.DataFrame = get_swissvotes_data())->pd.DataFrame:\n",
    "    import re\n",
    "    regex = re.compile(\".*_annahme\")\n",
    "    canton_names = list(filter(regex.match, data.columns))\n",
    "    return data[canton_names].replace('.', 0).astype(int)\n",
    "\n",
    "print(f\"Defined {get_canton_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c907f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volk_proz(data:pd.DataFrame=get_swissvotes_data())->pd.DataFrame:\n",
    "    temp = data[\"volkja_proz\"]\n",
    "    return temp / 100\n",
    "\n",
    "print(f\"Defined {get_volk_proz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb520f0e",
   "metadata": {},
   "source": [
    "## Training the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data    \n",
    "# the possible inputs for the neural net are:\n",
    "    # Rechtsform (one hot),\n",
    "    # Politikbereich (multi hot),\n",
    "    # Department (one hot),\n",
    "    # Position of the Bundesrat (one hot),\n",
    "    # legislatur (normalized from 1-10),\n",
    "    # Position of Nationalrat (one hot),\n",
    "    # Position of Ständerat (one hot),\n",
    "    # Party recommendations (one hot),\n",
    "    # left, right rating (one hot),\n",
    "    # conservative, liberal (one hot)\n",
    "# the possible outputs are:\n",
    "    # result of the votes (binary),\n",
    "    # result on a canton level (binary)\n",
    "    # yes percentage of the people ([0:1])\n",
    "def get_data(input_func:list=[get_rechtsform_onehot,\n",
    "                             get_politikbereich_multihot, \n",
    "                             get_department_onehot, \n",
    "                             get_parlament_onehot,\n",
    "                             get_legislatur,\n",
    "                             get_parlament_onehot,\n",
    "                             get_parlament_onehot,\n",
    "                             normalize_party_reco,\n",
    "                             get_l_r_onehot,\n",
    "                             get_kons_prog_onehot], \n",
    "            input_args:list=[None, \n",
    "                            None,\n",
    "                            None,\n",
    "                            get_swissvotes_data()[\"br_pos\"],\n",
    "                            None,\n",
    "                            None,\n",
    "                            get_swissvotes_data()[\"sr_pos\"],\n",
    "                            None,\n",
    "                            None,\n",
    "                            None],\n",
    "            output_func:list=[get_vote_result,\n",
    "                             get_canton_results,\n",
    "                             get_volk_proz],\n",
    "            output_args:list=[None,\n",
    "                             None,\n",
    "                             None]):\n",
    "    input_list = []\n",
    "    for f, a in zip(input_func, input_args):\n",
    "        if type(a) == type(None):\n",
    "            input_list.append(f())\n",
    "        else:\n",
    "            input_list.append(f(a))\n",
    "    \n",
    "    inputs = pd.concat(input_list, axis=1)\n",
    "    \n",
    "    out_list = []\n",
    "    for f, a in zip(output_func, output_args):\n",
    "        if type(a) == type(None):\n",
    "            out_list.append(f())\n",
    "        else:\n",
    "            out_list.append(f(a))\n",
    "    \n",
    "    outputs = pd.concat(out_list, axis=1)\n",
    "    \n",
    "    return get_swissvotes_data(), inputs, outputs\n",
    "\n",
    "print(f\"Defined {get_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d227986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(name:str, input_size:int = len(get_data()[1].columns), hidden:list=[100, 50, 20],\n",
    "                 output_size:int = len(get_data(output_func=[get_vote_result,get_canton_results], \n",
    "                                                output_args=[None,None])[2].columns), \n",
    "                 activation:str=\"relu\", activation_output:str=\"sigmoid\", \n",
    "                 optimizer=ks.optimizers.SGD(learning_rate=0.1), \n",
    "                 loss=ks.losses.BinaryCrossentropy(), \n",
    "                 metrics:list=[ks.metrics.BinaryAccuracy(), ks.metrics.FalseNegatives()])->ks.models.Sequential:\n",
    "    model = ks.models.Sequential()\n",
    "    \n",
    "    model.add(ks.layers.Dense(units=input_size, activation=activation, name=\"Input\"))\n",
    "    \n",
    "    for i in range(len(hidden)):\n",
    "        model.add(ks.layers.Dense(units=hidden[i], activation=activation, name=\"Hidden_\"+str(i)))\n",
    "        model.add(ks.layers.Dropout(rate=.1, name=\"Dropout_\"+str(i)))\n",
    "        \n",
    "    model.add(ks.layers.Dense(units=output_size, activation=activation_output, name=\"Output\"))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(f\"Defined {create_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d38517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:ks.models.Sequential, \n",
    "                inputs:pd.DataFrame=get_data()[1], \n",
    "                outputs:pd.DataFrame=get_data(output_func=[get_vote_result,get_canton_results], \n",
    "                                              output_args=[None,None])[2], \n",
    "                test_size:float=0.6, batch_size:int=50, epochs:int=125, shuffle:bool=True)->tuple:\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split as tss\n",
    "    in_train, in_test, out_train, out_test = tss(inputs, outputs, test_size=test_size)\n",
    "    \n",
    "    history = model.fit(x=in_train, y=out_train, batch_size=batch_size, epochs=epochs, shuffle=shuffle)\n",
    "    \n",
    "    return history, in_test, out_test\n",
    "\n",
    "print(f\"Defined {train_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e074bc",
   "metadata": {},
   "source": [
    "### Create and Train models\n",
    "\n",
    "There are two models. One for binary results and one for exact percentage of yes votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary = create_model(\"Binary Model\", metrics=[ks.metrics.MeanSquaredError(), ks.metrics.MeanAbsoluteError()])\n",
    "model_prcntg = create_model(\"Exact Model\", output_size=1, loss=ks.losses.MeanSquaredError(), \n",
    "                           metrics=[ks.metrics.RootMeanSquaredError(), ks.metrics.MeanSquaredLogarithmicError()])\n",
    "\n",
    "history_bin, in_test_bin, out_test_bin = train_model(model_binary)\n",
    "history_per, in_test_per, out_test_per = train_model(model_prcntg, \n",
    "                                                     outputs=get_data(output_func=[get_volk_proz], \n",
    "                                                                      output_args=[None])[2])\n",
    "\n",
    "print(model_binary.summary(), model_prcntg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff15b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Binary model results:\\t{model_binary.evaluate(x=in_test_bin, y=out_test_bin)}\")\n",
    "print(f\"Exact model results:\\t{model_prcntg.evaluate(x=in_test_per, y=out_test_per)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3e6ff",
   "metadata": {},
   "source": [
    "### Methods for Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca63cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classifier(inputs:pd.DataFrame=get_data()[1],\n",
    "                     outputs:pd.DataFrame=get_data()[2]['annahme'],\n",
    "                     test_size:float=0.2, cutoff:float=.5,\n",
    "                     shuffle:bool=False, scale_data:bool=False,\n",
    "                     visualisation:bool=True)->tuple:\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    cutoff=int(cutoff*len(inputs))\n",
    "    in_train, in_test, out_train, out_test = tts(inputs[cutoff:], outputs[cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    from sklearn.linear_model import SGDClassifier, RidgeClassifier, RidgeClassifierCV\n",
    "    from xgboost import XGBClassifier\n",
    "    #from fracridge import FracRidgeRegressor, FracRidgeRegressorCV\n",
    "    ridge = RidgeClassifier()\n",
    "    ridge.fit(in_train,out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(in_test)])\n",
    "    \n",
    "    ridgecv = RidgeClassifierCV()\n",
    "    ridgecv.fit(in_train,out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(in_test)])\n",
    "    \n",
    "    #fracridge = FracRidgeRegressor()\n",
    "    #fracridge.fit(in_train,out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(in_test)])\n",
    "    \n",
    "    #fracridgecv = FracRidgeRegressorCV()\n",
    "    #fracridgecv.fit(in_train,out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(in_test)])\n",
    "    \n",
    "    sgd = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "    sgd.fit(in_train, out_train)\n",
    "    out_pred.append([sgd,'sgd', sgd.predict(in_test)])\n",
    "    \n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(in_train, out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(in_test)])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        from sklearn.metrics import plot_confusion_matrix\n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            plot_confusion_matrix(i[0],in_test,out_test)\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proz_regression(inputs:pd.DataFrame=get_data()[1],\n",
    "                     outputs:pd.DataFrame=get_data()[2]['volkja_proz'],\n",
    "                     test_size:float=0.2, cutoff:float=.5,\n",
    "                     shuffle:bool=False, scale_data:bool=False,\n",
    "                     visualisation:bool=True)->tuple:\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    cutoff=int(cutoff*len(inputs))\n",
    "    in_train, in_test, out_train, out_test = tts(inputs[cutoff:], outputs[cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "        \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "    from xgboost import XGBRegressor\n",
    "    ridge = Ridge()\n",
    "    ridge.fit(in_train,out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(in_test)])\n",
    "    \n",
    "    ridgecv = RidgeCV()\n",
    "    ridgecv.fit(in_train,out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(in_test)])\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(in_train,out_train)\n",
    "    out_pred.append([lasso,'lasso', lasso.predict(in_test)])\n",
    "    \n",
    "    lassocv = LassoCV()\n",
    "    lassocv.fit(in_train,out_train)\n",
    "    out_pred.append([lassocv,'lassocv', lassocv.predict(in_test)])\n",
    "    \n",
    "    elasticnet = ElasticNet()\n",
    "    elasticnet.fit(in_train,out_train)\n",
    "    out_pred.append([elasticnet,'elasticnet', elasticnet.predict(in_test)])\n",
    "    \n",
    "    elasticnetcv = ElasticNetCV()\n",
    "    elasticnetcv.fit(in_train,out_train)\n",
    "    out_pred.append([elasticnetcv,'elasticnetcv', elasticnetcv.predict(in_test)])\n",
    "    \n",
    "    xgb = XGBRegressor()\n",
    "    xgb.fit(in_train,out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(in_test)])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classifier_iv(inputs:pd.DataFrame=get_data()[1], middle:pd.DataFrame=get_data()[2].drop(columns=['annahme','volkja_proz']),\n",
    "                  outputs:pd.DataFrame=get_data()[2]['annahme'],test_size:float=0.2, cutoff:float=.5,\n",
    "                  shuffle:bool=False, scale_data:bool=False,visualisation:bool=True)->tuple:\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    cutoff=int(cutoff*len(inputs))\n",
    "    in_train, in_test, mid_train, mid_test = tts(inputs[cutoff:], middle[cutoff:], test_size=0.01, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    #print(middle.columns)\n",
    "    mid_pred=[]\n",
    "    from sklearn.linear_model import SGDClassifier, RidgeClassifier, RidgeClassifierCV\n",
    "    from xgboost import XGBClassifier\n",
    "    #from fracridge import FracRidgeRegressor, FracRidgeRegressorCV\n",
    "    mid_ridge=[]\n",
    "    for i in middle.columns:\n",
    "        ridge = RidgeClassifier()\n",
    "        ridge.fit(in_train,mid_train[i])\n",
    "        mid_ridge.append(ridge.predict(inputs))\n",
    "    mid_ridge=np.transpose(mid_ridge)\n",
    "    mid_pred.append(pd.DataFrame(mid_ridge,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_ridgecv=[]\n",
    "    for i in middle.columns:\n",
    "        ridgecv = RidgeClassifierCV()\n",
    "        ridgecv.fit(in_train,mid_train[i])\n",
    "        mid_ridgecv.append(ridgecv.predict(inputs))\n",
    "    mid_ridgecv=np.transpose(mid_ridgecv)\n",
    "    mid_pred.append(pd.DataFrame(mid_ridgecv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    #mid_fracrdige=[]\n",
    "    #for i in middle.columns:\n",
    "    #    fracridge = FracRidgeRegressor()\n",
    "    #    fracridge.fit(in_train,mid_train[i])\n",
    "    #    mid_fracridge.append(fracridge.predict(inputs))\n",
    "    #mid_fracridge=np.transpose(mid_fracridge)\n",
    "    #mid_pred.append(pd.DataFrame(mid_fracridge,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    #mid_fracridgecv=[]\n",
    "    #for i in middle.columns:\n",
    "    #    fracridgecv = FracRidgeRegressorCV()\n",
    "    #    fracridgecv.fit(in_train,mid_train[i])\n",
    "    #    mid_fracridgecv.append(fracridgecv.predict(inputs))\n",
    "    #mid_fracridgecv=np.transpose(mid_fracridgecv)\n",
    "    #mid_pred.append(pd.DataFrame(mid_fracridgecv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_sgd=[]\n",
    "    for i in middle.columns:\n",
    "        sgd = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "        sgd.fit(in_train,mid_train[i])\n",
    "        mid_sgd.append(sgd.predict(inputs))\n",
    "    mid_sgd=np.transpose(mid_sgd)\n",
    "    mid_pred.append(pd.DataFrame(mid_sgd,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_xgb=[]\n",
    "    for i in middle.columns:\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(in_train,mid_train[i])\n",
    "        mid_xgb.append(xgb.predict(inputs))\n",
    "    mid_xgb=np.transpose(mid_xgb)\n",
    "    mid_pred.append(pd.DataFrame(mid_xgb,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_train = [] \n",
    "    mid_test = []\n",
    "    for i in np.arange(0,len(mid_pred)):\n",
    "        mid_t1, mid_t2 = tts(mid_pred[i][cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "        mid_train.append(mid_t1)\n",
    "        mid_test.append(mid_t2)\n",
    "    out_train, out_test = tts(outputs[cutoff:],test_size=test_size, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        for i in np.arange(0,len(mid_train)):\n",
    "            scaler = StandardScaler().fit(mid_train[i])\n",
    "            mid_train[i] = scaler.transform(mid_train[i])\n",
    "            mid_test[i] = scaler.transform(mid_test[i])\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    ridge = RidgeClassifier()\n",
    "    ridge.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(mid_test.pop(0))])\n",
    "    \n",
    "    ridgecv = RidgeClassifierCV()\n",
    "    ridgecv.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(mid_test.pop(0))])\n",
    "    \n",
    "    #fracridge = FracRidgeRegressor()\n",
    "    #fracridge.fit(mid_train.pop(0),out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(mid_test.pop(0))])\n",
    "    \n",
    "    #fracridgecv = FracRidgeRegressorCV()\n",
    "    #fracridgecv.fit(mid_train.pop(0),out_train)\n",
    "    #out_pred.append([fracridge,'fracridge', fracridge.predict(mid_test.pop(0))])\n",
    "    \n",
    "    sgd = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "    sgd.fit(mid_train.pop(0), out_train)\n",
    "    out_pred.append([sgd,'sgd', sgd.predict(mid_test.pop(0))])\n",
    "    \n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(mid_train.pop(0), out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(mid_test.pop(0))])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            confusion_matrix(i[2],out_test)\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proz_regression_iv(inputs:pd.DataFrame=get_data()[1], middle:pd.DataFrame=get_data()[2].drop(columns=['annahme','volkja_proz']),\n",
    "                  outputs:pd.DataFrame=get_data()[2]['volkja_proz'],test_size:float=0.2, cutoff:float=.5,\n",
    "                  shuffle:bool=False, scale_data:bool=False,visualisation:bool=True)->tuple:\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    cutoff=int(cutoff*len(inputs))\n",
    "    in_train, in_test, mid_train, mid_test = tts(inputs[cutoff:], middle[cutoff:], test_size=0.01, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler().fit(in_train)\n",
    "        in_train = scaler.transform(in_train)\n",
    "        in_test = scaler.transform(in_test)\n",
    "    \n",
    "    mid_pred=[]\n",
    "    from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "    from xgboost import XGBRegressor    \n",
    "\n",
    "    mid_ridge=[]\n",
    "    for i in middle.columns:\n",
    "        ridge = Ridge()\n",
    "        ridge.fit(in_train,mid_train[i])\n",
    "        mid_ridge.append(ridge.predict(inputs))\n",
    "    mid_ridge=np.transpose(mid_ridge)\n",
    "    mid_pred.append(pd.DataFrame(mid_ridge,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_ridgecv=[]\n",
    "    for i in middle.columns:\n",
    "        ridgecv = RidgeCV()\n",
    "        ridgecv.fit(in_train,mid_train[i])\n",
    "        mid_ridgecv.append(ridgecv.predict(inputs))\n",
    "    mid_ridgecv=np.transpose(mid_ridgecv)\n",
    "    mid_pred.append(pd.DataFrame(mid_ridgecv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_lasso=[]\n",
    "    for i in middle.columns:\n",
    "        lasso = Lasso()\n",
    "        lasso.fit(in_train,mid_train[i])\n",
    "        mid_lasso.append(lasso.predict(inputs))\n",
    "    mid_lasso=np.transpose(mid_lasso)\n",
    "    mid_pred.append(pd.DataFrame(mid_lasso,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_lassocv=[]\n",
    "    for i in middle.columns:\n",
    "        lassocv = LassoCV()\n",
    "        lassocv.fit(in_train,mid_train[i])\n",
    "        mid_lassocv.append(lassocv.predict(inputs))\n",
    "    mid_lassocv=np.transpose(mid_lassocv)\n",
    "    mid_pred.append(pd.DataFrame(mid_lassocv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_elasticnet=[]\n",
    "    for i in middle.columns:\n",
    "        elasticnet = ElasticNet()\n",
    "        elasticnet.fit(in_train,mid_train[i])\n",
    "        mid_elasticnet.append(elasticnet.predict(inputs))\n",
    "    mid_elasticnet=np.transpose(mid_elasticnet)\n",
    "    mid_pred.append(pd.DataFrame(mid_elasticnet,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_elasticnetcv=[]\n",
    "    for i in middle.columns:\n",
    "        elasticnetcv = ElasticNetCV()\n",
    "        elasticnetcv.fit(in_train,mid_train[i])\n",
    "        mid_elasticnetcv.append(elasticnetcv.predict(inputs))\n",
    "    mid_elasticnetcv=np.transpose(mid_elasticnetcv)\n",
    "    mid_pred.append(pd.DataFrame(mid_elasticnetcv,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_xgb=[]\n",
    "    for i in middle.columns:\n",
    "        xgb = XGBRegressor()\n",
    "        xgb.fit(in_train,mid_train[i])\n",
    "        mid_xgb.append(xgb.predict(inputs))\n",
    "    mid_xgb=np.transpose(mid_xgb)\n",
    "    mid_pred.append(pd.DataFrame(mid_xgb,columns=middle.columns,index=middle.index))\n",
    "    \n",
    "    mid_train = [] \n",
    "    mid_test = []\n",
    "    for i in np.arange(0,len(mid_pred)):\n",
    "        mid_t1, mid_t2 = tts(mid_pred[i][cutoff:], test_size=test_size, shuffle=shuffle)\n",
    "        mid_train.append(mid_t1)\n",
    "        mid_test.append(mid_t2)\n",
    "    out_train, out_test = tts(outputs[cutoff:],test_size=test_size, shuffle=shuffle)\n",
    "    \n",
    "    if(scale_data):\n",
    "        for i in np.arange(0,len(mid_train)):\n",
    "            scaler = StandardScaler().fit(mid_train[i])\n",
    "            mid_train[i] = scaler.transform(mid_train[i])\n",
    "            mid_test[i] = scaler.transform(mid_test[i])\n",
    "    \n",
    "    out_pred = []\n",
    "    \n",
    "    ridge = Ridge()\n",
    "    ridge.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([ridge,'ridge', ridge.predict(mid_test.pop(0))])\n",
    "    \n",
    "    ridgecv = RidgeCV()\n",
    "    ridgecv.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([ridgecv,'ridgecv', ridgecv.predict(mid_test.pop(0))])\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([lasso,'lasso', lasso.predict(mid_test.pop(0))])\n",
    "    \n",
    "    lassocv = LassoCV()\n",
    "    lassocv.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([lassocv,'lassocv', lassocv.predict(mid_test.pop(0))])\n",
    "    \n",
    "    elasticnet = ElasticNet()\n",
    "    elasticnet.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([elasticnet,'elasticnet', elasticnet.predict(mid_test.pop(0))])\n",
    "    \n",
    "    elasticnetcv = ElasticNetCV()\n",
    "    elasticnetcv.fit(mid_train.pop(0),out_train)\n",
    "    out_pred.append([elasticnetcv,'elasticnetcv', elasticnetcv.predict(mid_test.pop(0))])\n",
    "    \n",
    "    xgb = XGBRegressor()\n",
    "    xgb.fit(mid_train.pop(0), out_train)\n",
    "    out_pred.append([xgb,'xgb', xgb.predict(mid_test.pop(0))])\n",
    "    \n",
    "    if(visualisation):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        from xgboost import plot_importance\n",
    "        errors = []\n",
    "        errors.append(['r2_score', r2_score])\n",
    "        errors.append(['mse', mean_squared_error])\n",
    "        errors.append(['mae', mean_absolute_error])\n",
    "        \n",
    "        for i in out_pred:\n",
    "            print(i[1], ': ')\n",
    "            for j in errors:\n",
    "                print(j[0], j[1](i[2],out_test),' ')\n",
    "            print('\\n')\n",
    "    \n",
    "        fig, ax = plt.subplots(len(out_pred),1, figsize=(20,30))\n",
    "        axe = ax.ravel()\n",
    "        for i in range(0,len(out_pred)):\n",
    "            sns.regplot(ax=axe[i], x=out_pred[i][2], y=out_test, x_bins=100)\n",
    "            axe[i].set_title(out_pred[i][1])\n",
    "            axe[i].set_xlabel('recommendations')\n",
    "            axe[i].set_ylabel('Passed')\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (15, 20)\n",
    "        plot_importance(xgb)\n",
    "        plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "            \n",
    "    return out_pred, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(inputs:pd.DataFrame=get_data()[1],\n",
    "          outputs:pd.DataFrame=get_data()[2],\n",
    "         x:str='legislatur', y:str='annahme'):\n",
    "    fig, ax = plt.subplots(3,1, figsize=(20,30))\n",
    "    ax[0].hist(inputs[x], bins=34)\n",
    "    \n",
    "    ax[1].hist(outputs[y], bins=34)\n",
    "    \n",
    "    ax[2]=sns.lineplot(x=inputs[x], y=outputs[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(y=\"volkja_proz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proz_regression_iv(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c38f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proz_regression_iv(shuffle=False,cutoff=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acdced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary_classifier_iv(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f90245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary_classifier_iv(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e3023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
